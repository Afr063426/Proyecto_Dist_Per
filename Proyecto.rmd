---
title: "Untitled"
author: "Daniel Sabater"
date: "2022-09-28"
output: html_document
---


```{r setup, include=FALSE}
#We are going to load the packages required for the project
options(scipen=999)
library(tidyverse) #Data manipulation
library(lubridate)
library(readr)


library(qqplotr) # for qqplot
#For extreme value estimation of parameters. It uses 
#MLE, this estimation can have some problems with
#estimation in small samples.
library(evd)
library(rBayesianOptimization)
library(kdensity)

##Alternatives
#evir, extRemes, fExtremes, and POT 

#fExtremes allow employ Probability 
#Weighted Moments method. It can
#be  useful for small smaples

setwd("C:/Users/saac9/OneDrive - Universidad de Costa Rica/Documents/UCR/2022/Distribuciones_de_Perdidas/Proyecto_Dist_Per")
base_de_datos <- read_csv("base_de_datos.csv")
base_de_datos<-base_de_datos %>%select(-c(`REGION / TOWN`,FinYeae ))
base_de_datos<-base_de_datos[-c(12:length(base_de_datos))]

base_de_datos<-base_de_datos[!(is.na(base_de_datos$Type)|base_de_datos$Type=="Other"|base_de_datos$Type=="East Coast Low"|base_de_datos$Type=="Wind"),]

base_de_datos$`CAT EVENT START`<-as.Date(base_de_datos$`CAT EVENT START`, "%m/%d/%y")
base_de_datos$`CAT EVENT FINISH`<-as.Date(base_de_datos$`CAT EVENT FINISH`, "%m/%d/%y")

base_de_datos$Type<-as.factor(base_de_datos$Type)

base_de_datos$YEAR<-as.numeric(base_de_datos$YEAR)
base_de_datos$`ORIGINAL LOSS VALUE`<-as.numeric(base_de_datos$`ORIGINAL LOSS VALUE`)
base_de_datos$`NORMALISED LOSS VALUE (2017)`<-as.numeric(base_de_datos$`NORMALISED LOSS VALUE (2017)`)



base_de_datos$Type<-recode_factor(base_de_datos$Type, "Bushfire"="Incendio forestal",
                                  "Cyclone" = "Ciclón", "Earthquake"="Terremoto",
                                  "Flooding"="Inundación",  "Hailstorm" ="Granizada", 
                                  "Storm"="Tormenta" )


base_de_datos$`NORMALISED LOSS VALUE (2017)`[is.na(base_de_datos$`NORMALISED LOSS VALUE (2017)`) ]<-0

base_de_datos<-base_de_datos[base_de_datos$`NORMALISED LOSS VALUE (2017)`>1,]


```


```{r, fig.align="center",fig.width=11, fig.height=7, echo=FALSE, message=FALSE, warning=FALSE,fig.cap='titulo'}
CantidadPorAno <-
  as.data.frame(base_de_datos %>% group_by(Type) %>% count(YEAR))

imagen1<-CantidadPorAno %>% ggplot(aes(
  x = YEAR,
  y = n,
  group = Type,
  color = Type
)) +
  geom_line(size = 1.25) +
  scale_color_discrete(name = "Tipo") +
  facet_wrap( ~ Type,
              ncol = 2,
              dir = "v",
              scales = "free_y" ) +
  labs(y = "Cantidad", x = "Año") +
  scale_x_continuous(breaks = seq(min(CantidadPorAno$YEAR), max(CantidadPorAno$YEAR), 5),
                     minor_breaks = seq(0, 16, 1), ) +
  scale_fill_brewer(palette = "Set2") +
  scale_color_brewer(palette = "Set2") +
  theme_minimal() +
  theme(
    text =  element_text(size = 17),
    legend.position = "none",
    plot.caption = element_text(hjust = 0),
    axis.text.x = element_text(angle = 25),
    panel.spacing = unit(0.65, "cm"),
    strip.text = element_text(size = 17)
  )
imagen1
ggsave(file="CantidadporAno.pdf", plot=imagen1, width=11, height=7)

```

```{r, fig.align="center",fig.width=11, fig.height=7, echo=FALSE, message=FALSE, warning=FALSE,fig.cap='titulo'}
names(CantidadPorAno)<-c("Tipo","año","cantidad")
cantidad_de_años_con_la_misma_cantidad_de_tornados<-as.data.frame(CantidadPorAno%>% group_by(Tipo) %>% count(cantidad))

#Frecuencia del numero de eventos por año

imagen1<-cantidad_de_años_con_la_misma_cantidad_de_tornados%>%ggplot(aes(x=cantidad, y = n,group=Tipo, color=Tipo, fill=Tipo))+
  geom_bar(
    stat = "identity",
    width = 0.75,
    position = position_dodge2(width = 20, preserve = "single")
  ) +
  scale_x_continuous(breaks = seq(0, 16, 1),
                     minor_breaks = seq(0, 16, 1)) +
  scale_y_continuous(breaks = seq(
    0,
    length(cantidad_de_años_con_la_misma_cantidad_de_tornados$n),
    2
  ),
  minor_breaks = seq(
    0,
    length(cantidad_de_años_con_la_misma_cantidad_de_tornados$n),
    1
  )) +
  scale_fill_brewer(palette = "Set2") +
  scale_color_brewer(palette = "Set2") +
  labs(x = "Número de eventos", y = "Frecuencia a través de los años") +
  guides(color = guide_legend(title = "Tipo de evento"),
         fill = guide_legend("Tipo de evento")) +
  theme_minimal() +
  theme(
    legend.position = "bottom",
    plot.caption = element_text(hjust = 0),
    text =  element_text(size = 16)
  )

imagen1
ggsave(file="FrecuencPorAno.pdf", plot=imagen1, width=11, height=7)
```
 


```{r, fig.align="center",fig.width=11, fig.height=7, echo=FALSE, message=FALSE, warning=FALSE,fig.cap='titulo'}
imagen1<-base_de_datos%>%ggplot(aes(y = Type, x = `NORMALISED LOSS VALUE (2017)`/1000000, group=Type, color=Type)) +
  geom_boxplot(aes(color = Type), alpha = 1) +
  stat_boxplot(geom='errorbar', linetype=1, width=0.5)+
  geom_jitter(aes(color = Type), size = 1, alpha = 0.09)+
  scale_color_discrete(name = "Type")+
  stat_summary(fun.y=mean, geom="point", shape=18,size=3)+
  #facet_wrap(~ Type,ncol = 2,dir = "v",scales = "free" )+
  scale_x_continuous(breaks=seq(0, max(base_de_datos$`NORMALISED LOSS VALUE (2017)`, na.rm = T)/1000000, 1000/2))+
  scale_fill_brewer(palette="Set2")+
  scale_color_brewer(palette="Set2")+
  labs( y='',x='Montos de perdidas (en millones de dólares australianos)')+
  guides(color=guide_legend(title="Tipo de evento"),fill=guide_legend("Tipo de evento")) +
  theme_minimal()+
  theme(
        legend.position="none",
        plot.caption = element_text(hjust = 0),
        text =  element_text(size=17))
imagen1
ggsave(file="PerdidasConjunta.pdf", plot=imagen1, width=11, height=7)
```



```{r, fig.align="center",fig.width=11, fig.height=7, echo=FALSE, message=FALSE, warning=FALSE,fig.cap='titulo'}
imagen1<-base_de_datos %>% ggplot(aes(
  y = Type,
  x = `NORMALISED LOSS VALUE (2017)` / 1000000,
  group = Type,
  color = Type
)) +
  geom_boxplot(aes(color = Type), alpha = 1) +
  stat_boxplot(geom = 'errorbar',
               linetype = 1,
               width = 0.5) +
  geom_jitter(aes(color = Type), size = 1, alpha = 0.09) +
  scale_color_discrete(name = "Type") +
  stat_summary(
    fun.y = mean,
    geom = "point",
    shape = 18,
    size = 3
  ) +
  facet_wrap( ~ Type,
              #ncol = 2,
              #dir = "v",
              scales = "free") +
  scale_fill_brewer(palette = "Set2") +
  scale_color_brewer(palette = "Set2") +
  scale_x_continuous(n.breaks = 6) +
  labs(y = '', x = 'Montos de perdidas (en millones de dólares australianos)') +
  theme_minimal() +
  theme(
    axis.text.y = element_blank(),
    legend.position = "none",
    plot.caption = element_text(hjust = 0),
    text =  element_text(size = 17),
    strip.text = element_text(size = 17),
    panel.spacing = unit(0.75, "cm")
  )
imagen1
ggsave(file="PerdidasIndividuales.pdf", plot=imagen1, width=11, height=7)
```



```{r, fig.align="center",fig.width=11, fig.height=7, echo=FALSE, message=FALSE, warning=FALSE,fig.cap='titulo'}
imagen1<-base_de_datos %>% ggplot(aes(
  x = `NORMALISED LOSS VALUE (2017)` / 1000000,
  group = Type,
  color = Type,
  fill = Type)) +
  #geom_density(alpha = 0.7) +
  geom_histogram()+
  scale_x_continuous(n.breaks = 6) +
  scale_fill_brewer(palette = "Set2") +
  scale_color_brewer(palette = "Set2") +
  facet_wrap( ~ Type
              #, scales = "free"
              ) +
  labs(x = "Montos de perdidas (en millones de dólares australianos)", y = "Frecuencia") +
  theme_minimal() +
  theme(
    legend.position = "none",
    plot.caption = element_text(hjust = 0.5),
    text =  element_text(size = 17),
    strip.text = element_text(size = 17),
    panel.spacing = unit(0.75, "cm")
  )
imagen1
ggsave(file="PerdidasHistrograma.pdf", plot=imagen1, width=11, height=7)
```




































## Model employing Machine Learning
```{r}
#Estimation function by kernel density
#We create a function that estimate de parameteres
#employing MLE and POT method
#X is the data
#u is the threshold
#x is the parameter that wants to be
#estimated


GPD_MLE <- function(X,u){
  model <- evd::fpot(x=X,threshold = u, model = "gpd",std.err=FALSE) #Fit the parameters
  scale <- model$estimate[1]
  shape <- model$estimate[2]
  return(c(shape,scale)) #We return the value
}

norm_L_1_GPD_KDE <- function(X,eps=0,iter=1000){
  m <- min(X[X>0],na.rm=TRUE)
  #print(m)
  M <- max(X, na.rm=TRUE)
  M <- max(X[X<M])
  fn <- function(u){
    
    kde <- kdensity(X[X>=u],kernel="gaussian",normalized=FALSE)
    #print(u)
    GPD_params <- GPD_MLE(X,u)
    #print(GPD_params)
    F_kde_u <-  integrate(function(x) kde(x-eps),lower=eps,upper = Inf)$value
    integral <- integrate(function(x) abs(kde(x)/(F_kde_u)-evd::dgpd(x,loc=u,scale=GPD_params[2],shape= GPD_params[1],log=FALSE)),lower = u,upper=Inf)$value
    
    return(integral)
    
  }
  #return(BayesianOptimization(FUN=fn,bounds = list(u=c(m,M)),n_iter=iter))
  optim(par=m,fn,lower=m,upper=M, method="Brent")
  
}




parameters <- function(X,eps=0,iter=1000){
  M <- max(X)
  Y <- X/M
  p <- norm_L_1_GPD_KDE(Y,eps=eps,iter=iter)
  GPD_params <- GPD_MLE(X,u=p$par*M)
  return(list(shape=GPD_params[1],scale=GPD_params[2],u=p$par*M,error=p$value))
}


estimation_nakamura <- data.frame("Evento"=character(),shape = numeric(),scale=numeric(),u=numeric(),error=numeric())
events <- unique(base_de_datos$Type)

for (i in events){
  data_model <- base_de_datos%>%filter(Type == i)
  X <- t(data_model%>%select(`NORMALISED LOSS VALUE (2017)`))
  X[is.na(X)] <- 0 
  #print(length(X))
  #print(X)
  estimation <- parameters(X)
  estimation_nakamura <- rbind(estimation_nakamura, data.frame("Evento"=i,shape = estimation$shape,scale=estimation$scale,u=estimation$u,error=estimation$error))
}

#ejemplo <- estimation_nakamura[1,]
#M<- t(base_de_datos%>%filter(Type == events[1])%>%select(`NORMALISED LOSS VALUE (2017)`))
#M[is.na(M)] <- 0
#for_hist <- M[M>=ejemplo$u]
#M <- max(M,na.rm=TRUE)
#ggplot(,)+xlim(0,M+1)+stat_function(fun = evd::dgpd,args=list(shape=ejemplo$shape,loc=ejemplo$u,scale=ejemplo$scale))+geom_his


create_qqplot <- function(data,distribution,list_params){
        plot <- ggplot(,aes(sample=data)) + stat_qq_line(distribution = "gpd", dparams= list_params) + stat_qq_point(distribution = "gpd", dparams = list_params)
        return(plot)
}

M<- t(base_de_datos%>%filter(Type == events[4])%>%select(`NORMALISED LOSS VALUE (2017)`))
M[is.na(M)] <- 0
for_hist <- M[M>=estimation_nakamura$u[2]]
create_qqplot(data=for_hist,distribution="gpd",list(shape=estimation_nakamura$shape[2],scale=estimation_nakamura$scale[2],loc=estimation_nakamura$u[2]))

u<-seq(min(M),max(M),by=100000)
prueba<-numeric()
for(j in (1:length(u))){
prueba[j] <- mean(M[M>u[j]]) #Fit the parameters
}
plot(x=u,prueba)
```
















